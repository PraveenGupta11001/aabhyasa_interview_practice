{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f286350f",
   "metadata": {},
   "source": [
    "celery -A celery_app worker --loglevel=info\n",
    "celery -A celery_app beat --loglevel=info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a59c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3892ccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Required fields: ['name', 'email', 'message']\n",
      "[INFO] 'name' not found, scrolling...\n",
      "[FOUND] 'name' at (1012, 513) (attempt 2)\n"
     ]
    }
   ],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pyautogui\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go one level up from the notebook folder\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from img_to_text.ocr import extract_text_strong\n",
    "\n",
    "# ===== CONFIG =====\n",
    "URL = \"https://portfolio-praveen-gupta.vercel.app/\"\n",
    "# URL = \"https://practice.expandtesting.com/contact?utm_source=chatgpt.com\"\n",
    "SCROLL_AMOUNT = -50\n",
    "SCROLL_DELAY = 0.2\n",
    "SCROLL_LIMIT = 200\n",
    "\n",
    "# --- Screenshot helper ---\n",
    "def take_screenshot():\n",
    "    screenshot_path = \"/home/praveen/Desktop/My-Projects/interview_p/imgs/outputs/screen.png\"\n",
    "    time.sleep(0.5)\n",
    "    subprocess.run([\"gnome-screenshot\", \"-f\", screenshot_path])\n",
    "    return screenshot_path\n",
    "\n",
    "# --- OCR extraction ---\n",
    "def extract_text(image_path):\n",
    "    return extract_text_strong(image_path)  # use your function directly\n",
    "\n",
    "# --- Find coordinates of text in image ---\n",
    "def find_text_coordinate_in_image(image_path, search_text):\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    img = img.point(lambda x: 0 if x < 130 else 255)\n",
    "\n",
    "    boxes = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "    for i in range(len(boxes['text'])):\n",
    "        if search_text.lower() in boxes['text'][i].lower():\n",
    "            x, y, w, h = boxes['left'][i], boxes['top'][i] + 25, boxes['width'][i], boxes['height'][i] + 25\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            return (center_x, center_y)\n",
    "    return None\n",
    "\n",
    "# --- Fill field and press Tab ---\n",
    "def fill_field(value):\n",
    "    pyautogui.typewrite(value)\n",
    "    pyautogui.press(\"tab\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Allow nested event loops (needed for Jupyter/IPython)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def fetch_form():\n",
    "    session = AsyncHTMLSession()\n",
    "    webbrowser.open(URL)\n",
    "\n",
    "    r = await session.get(URL)\n",
    "    await r.html.arender(timeout=20, sleep=2)\n",
    "\n",
    "    soup = BeautifulSoup(r.html.html, \"html.parser\")\n",
    "    form = soup.find(\"form\")\n",
    "\n",
    "    if not form:\n",
    "        print(\"[ERROR] No form found on page.\")\n",
    "        return []\n",
    "\n",
    "    fields_bs4 = form.find_all([\"input\", \"textarea\"])\n",
    "    field_names = []\n",
    "    for tag in fields_bs4:\n",
    "        if tag.get(\"type\") in [\"submit\", \"hidden\", \"checkbox\", \"radio\"]:\n",
    "            continue\n",
    "        placeholder = tag.get(\"name\") or tag.get(\"name\") or tag.get(\"id\") or tag.text\n",
    "        if placeholder:\n",
    "            field_names.append(placeholder.strip())\n",
    "\n",
    "    print(\"[INFO] Required fields:\", field_names)\n",
    "    return field_names\n",
    "\n",
    "async def main():\n",
    "    field_names = await fetch_form()\n",
    "    if not field_names:\n",
    "        return\n",
    "\n",
    "    # Prepare input data safely\n",
    "    input_data = {}\n",
    "    if len(field_names) >= 3:\n",
    "        input_data = {\n",
    "            field_names[0]: \"John Doe\",\n",
    "            field_names[1]: \"john@example.com\",\n",
    "            field_names[2]: \"This is a test message\"\n",
    "        }\n",
    "    else:\n",
    "        for name in field_names:\n",
    "            input_data[name] = f\"Sample for {name}\"\n",
    "\n",
    "    # Locate first field by OCR\n",
    "    target_label = field_names[0]\n",
    "    coord = None\n",
    "    for attempt in range(SCROLL_LIMIT):\n",
    "        shot = take_screenshot()\n",
    "        coord = find_text_coordinate_in_image(shot, target_label)\n",
    "        if coord:\n",
    "            print(f\"[FOUND] '{target_label}' at {coord} (attempt {attempt+1})\")\n",
    "            pyautogui.click(coord[0], coord[1])\n",
    "            fill_field(input_data[target_label])\n",
    "            input_data[target_label] = \"\"  # mark filled\n",
    "            break\n",
    "        print(f\"[INFO] '{target_label}' not found, scrolling...\")\n",
    "        pyautogui.scroll(SCROLL_AMOUNT)\n",
    "        time.sleep(SCROLL_DELAY)\n",
    "\n",
    "    # Fill remaining fields sequentially via Tab\n",
    "    for fname, fvalue in input_data.items():\n",
    "        if fvalue:\n",
    "            fill_field(fvalue)\n",
    "\n",
    "    # Press Enter to submit\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "# Run the main function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da8628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Required fields: ['Name', 'Email', 'You message']\n",
      "[FOUND] 'Name' at (379, 615) (attempt 1)\n"
     ]
    }
   ],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pyautogui\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go one level up from the notebook folder\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from img_to_text.ocr import extract_text_strong\n",
    "\n",
    "# ===== CONFIG =====\n",
    "URL = \"https://portfolio-praveen-gupta.vercel.app/\"\n",
    "URL = \"https://practice.expandtesting.com/contact?utm_source=chatgpt.com\"\n",
    "SCROLL_AMOUNT = -50\n",
    "SCROLL_DELAY = 0.2\n",
    "SCROLL_LIMIT = 200\n",
    "\n",
    "# --- Screenshot helper ---\n",
    "def take_screenshot():\n",
    "    screenshot_path = \"/home/praveen/Desktop/My-Projects/interview_p/imgs/outputs/screen.png\"\n",
    "    time.sleep(0.1)\n",
    "    subprocess.run([\"gnome-screenshot\", \"-f\", screenshot_path])\n",
    "    return screenshot_path\n",
    "\n",
    "# --- OCR extraction ---\n",
    "def extract_text(image_path):\n",
    "    return extract_text_strong(image_path)  # use your function directly\n",
    "\n",
    "# --- Find coordinates of text in image ---\n",
    "def find_text_coordinate_in_image(image_path, search_text):\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    img = img.point(lambda x: 0 if x < 130 else 255)\n",
    "\n",
    "    boxes = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "    for i in range(len(boxes['text'])):\n",
    "        if search_text.lower() in boxes['text'][i].lower():\n",
    "            x, y, w, h = boxes['left'][i], boxes['top'][i] + 25, boxes['width'][i], boxes['height'][i] + 25\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            return (center_x, center_y)\n",
    "    return None\n",
    "\n",
    "# --- Fill field and press Tab ---\n",
    "def fill_field(value):\n",
    "    pyautogui.typewrite(value)\n",
    "    pyautogui.press(\"tab\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Allow nested event loops (needed for Jupyter/IPython)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def fetch_form():\n",
    "    session = AsyncHTMLSession()\n",
    "    webbrowser.open(URL)\n",
    "\n",
    "    r = await session.get(URL)\n",
    "    await r.html.arender(timeout=20, sleep=1)\n",
    "\n",
    "    soup = BeautifulSoup(r.html.html, \"html.parser\")\n",
    "    \n",
    "\n",
    "    fields_bs4 = soup.find_all(class_='form-label')\n",
    "    field_names = []\n",
    "    for tag in fields_bs4:\n",
    "        if tag.get(\"type\") in [\"submit\", \"hidden\", \"checkbox\", \"radio\"]:\n",
    "            continue\n",
    "        placeholder = tag.text.strip()\n",
    "        if placeholder:\n",
    "            field_names.append(placeholder.strip())\n",
    "\n",
    "    print(\"[INFO] Required fields:\", field_names)\n",
    "    return field_names\n",
    "\n",
    "async def main():\n",
    "    field_names = await fetch_form()\n",
    "    if not field_names:\n",
    "        return\n",
    "\n",
    "    # Prepare input data safely\n",
    "    input_data = {}\n",
    "    if len(field_names) >= 3:\n",
    "        input_data = {\n",
    "            field_names[0]: \"John Doe\",\n",
    "            field_names[1]: \"john@example.com\",\n",
    "            field_names[2]: \"This is a test message\"\n",
    "        }\n",
    "    else:\n",
    "        for name in field_names:\n",
    "            input_data[name] = f\"Sample for {name}\"\n",
    "\n",
    "    # Locate first field by OCR\n",
    "    target_label = field_names[0]\n",
    "    coord = None\n",
    "    for attempt in range(SCROLL_LIMIT):\n",
    "        shot = take_screenshot()\n",
    "        coord = find_text_coordinate_in_image(shot, target_label)\n",
    "        if coord:\n",
    "            print(f\"[FOUND] '{target_label}' at {coord} (attempt {attempt+1})\")\n",
    "            pyautogui.click(coord[0], coord[1])\n",
    "            fill_field(input_data[target_label])\n",
    "            input_data[target_label] = \"\"  # mark filled\n",
    "            break\n",
    "        print(f\"[INFO] '{target_label}' not found, scrolling...\")\n",
    "        pyautogui.scroll(SCROLL_AMOUNT)\n",
    "        time.sleep(SCROLL_DELAY)\n",
    "\n",
    "    # Fill remaining fields sequentially via Tab\n",
    "    for fname, fvalue in input_data.items():\n",
    "        if fvalue:\n",
    "            fill_field(fvalue)\n",
    "\n",
    "    # Press Enter to submit\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "# Run the main function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00127246",
   "metadata": {},
   "source": [
    "# another try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "339d93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import Output\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def find_input_box_coordinate(image_path, label_text,\n",
    "                              max_search_h=300,\n",
    "                              min_width=40,\n",
    "                              min_aspect=2.0,\n",
    "                              debug_save=None):\n",
    "    \"\"\"\n",
    "    Return screen-coordinate (x_center, y_center) of the input box nearest & below label_text.\n",
    "    If not found, returns a conservative fallback location (below label) or None.\n",
    "    debug_save: if provided, will save a debug image with overlayed boxes.\n",
    "    \"\"\"\n",
    "\n",
    "    # read color image and grayscale\n",
    "    color = cv2.imread(image_path)\n",
    "    if color is None:\n",
    "        return None\n",
    "    h_img, w_img = color.shape[:2]\n",
    "    gray = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # OCR to find label bounding box (pick highest-confidence match containing label_text)\n",
    "    boxes = pytesseract.image_to_data(gray, output_type=Output.DICT)\n",
    "    best_idx = None\n",
    "    best_conf = -999.0\n",
    "    for i, txt in enumerate(boxes['text']):\n",
    "        if not txt or txt.strip() == \"\":\n",
    "            continue\n",
    "        if label_text.lower() in txt.lower():\n",
    "            try:\n",
    "                conf = float(boxes['conf'][i])\n",
    "            except:\n",
    "                conf = 0.0\n",
    "            if conf > best_conf:\n",
    "                best_conf = conf\n",
    "                best_idx = i\n",
    "\n",
    "    if best_idx is None:\n",
    "        # Label not found\n",
    "        return None\n",
    "\n",
    "    lx = int(boxes['left'][best_idx])\n",
    "    ly = int(boxes['top'][best_idx])\n",
    "    lw = int(boxes['width'][best_idx])\n",
    "    lh = int(boxes['height'][best_idx])\n",
    "    label_bottom = ly + lh\n",
    "\n",
    "    # Define ROI: area below the label where the input box likely sits\n",
    "    roi_y1 = label_bottom\n",
    "    roi_y2 = min(h_img, roi_y1 + max_search_h)\n",
    "    roi_x1 = max(0, lx - 80)                          # allow some left margin\n",
    "    roi_x2 = min(w_img, lx + lw + 300)                # allow some right margin\n",
    "\n",
    "    roi = gray[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    if roi.size == 0:\n",
    "        return None\n",
    "\n",
    "    # Preprocess ROI for contour detection\n",
    "    blur = cv2.GaussianBlur(roi, (3,3), 0)\n",
    "    th = cv2.adaptiveThreshold(blur, 255,\n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY_INV, 15, 8)  # invert makes boxes white\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in ROI\n",
    "    contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    candidates = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w < min_width or h < 8:\n",
    "            continue\n",
    "        aspect = w / float(h) if h>0 else 0\n",
    "        if aspect < min_aspect:\n",
    "            continue\n",
    "        # map to full-image coordinates\n",
    "        ax = x + roi_x1\n",
    "        ay = y + roi_y1\n",
    "        candidates.append((ax, ay, w, h))\n",
    "\n",
    "    # Keep only candidates that are below the label\n",
    "    candidates = [c for c in candidates if c[1] > label_bottom - 2]\n",
    "\n",
    "    # Score candidates: prefer small vertical distance below label and good horizontal overlap\n",
    "    def score_candidate(c):\n",
    "        ax, ay, aw, ah = c\n",
    "        vert_dist = ay - label_bottom if ay >= label_bottom else 9999\n",
    "        # horizontal overlap measure (negative if no overlap)\n",
    "        overlap = max(0, min(ax+aw, lx+lw) - max(ax, lx))\n",
    "        # prefer overlap; penalize if no overlap\n",
    "        overlap_penalty = 0 if overlap>0 else 200\n",
    "        return vert_dist + overlap_penalty\n",
    "\n",
    "    if candidates:\n",
    "        candidates.sort(key=score_candidate)\n",
    "        best = candidates[0]\n",
    "        bx, by, bw, bh = best\n",
    "        center_x = bx + bw // 2\n",
    "        center_y = by + bh // 2\n",
    "\n",
    "        # save debug image optionally\n",
    "        if debug_save:\n",
    "            pil = Image.fromarray(cv2.cvtColor(color, cv2.COLOR_BGR2RGB))\n",
    "            draw = ImageDraw.Draw(pil)\n",
    "            # label box (green)\n",
    "            draw.rectangle([(lx, ly), (lx+lw, ly+lh)], outline=\"green\", width=2)\n",
    "            # ROI (blue)\n",
    "            draw.rectangle([(roi_x1, roi_y1), (roi_x2, roi_y2)], outline=\"blue\", width=1)\n",
    "            # best input (red)\n",
    "            draw.rectangle([(bx, by), (bx+bw, by+bh)], outline=\"red\", width=3)\n",
    "            pil.save(debug_save)\n",
    "\n",
    "        return (center_x, center_y)\n",
    "\n",
    "    # Fallback: no detected candidate â€” return conservative point slightly below label\n",
    "    fallback_x = lx + lw // 2\n",
    "    fallback_y = label_bottom + max(20, int(lh*1.2))\n",
    "    if debug_save:\n",
    "        pil = Image.fromarray(cv2.cvtColor(color, cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(pil)\n",
    "        draw.rectangle([(lx, ly), (lx+lw, ly+lh)], outline=\"green\", width=2)\n",
    "        draw.text((lx, ly - 12), \"fallback\", fill=\"yellow\")\n",
    "        pil.save(debug_save)\n",
    "    return (fallback_x, fallback_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Required fields: ['Name', 'Email', 'You message']\n",
      "[FOUND] 'Name' at (379, 578) (attempt 1)\n"
     ]
    }
   ],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageDraw\n",
    "import pyautogui\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go one level up from the notebook folder\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from img_to_text.ocr import extract_text_strong\n",
    "\n",
    "# ===== CONFIG =====\n",
    "URL = \"https://portfolio-praveen-gupta.vercel.app/\"\n",
    "URL = \"https://practice.expandtesting.com/contact?utm_source=chatgpt.com\"\n",
    "SCROLL_AMOUNT = -50\n",
    "SCROLL_DELAY = 0.2\n",
    "SCROLL_LIMIT = 200\n",
    "\n",
    "# --- Screenshot helper ---\n",
    "def take_screenshot():\n",
    "    screenshot_path = \"/home/praveen/Desktop/My-Projects/interview_p/imgs/outputs/screen.png\"\n",
    "    time.sleep(0.5)\n",
    "    subprocess.run([\"gnome-screenshot\", \"-f\", screenshot_path])\n",
    "    return screenshot_path\n",
    "\n",
    "# --- OCR extraction ---\n",
    "def extract_text(image_path):\n",
    "    return extract_text_strong(image_path)  # use your function directly\n",
    "\n",
    "# --- Find coordinates of text in image ---\n",
    "###############################\n",
    "\n",
    "# --- Fill field and press Tab ---\n",
    "def fill_field(value):\n",
    "    pyautogui.typewrite(value)\n",
    "    pyautogui.press(\"tab\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Allow nested event loops (needed for Jupyter/IPython)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def fetch_form():\n",
    "    session = AsyncHTMLSession()\n",
    "    webbrowser.open(URL)\n",
    "\n",
    "    r = await session.get(URL)\n",
    "    await r.html.arender(timeout=20, sleep=1)\n",
    "\n",
    "    soup = BeautifulSoup(r.html.html, \"html.parser\")\n",
    "    \n",
    "\n",
    "    fields_bs4 = soup.find_all(class_='form-label')\n",
    "    field_names = []\n",
    "    for tag in fields_bs4:\n",
    "        if tag.get(\"type\") in [\"submit\", \"hidden\", \"checkbox\", \"radio\"]:\n",
    "            continue\n",
    "        placeholder = tag.text.strip()\n",
    "        if placeholder:\n",
    "            field_names.append(placeholder.strip())\n",
    "\n",
    "    print(\"[INFO] Required fields:\", field_names)\n",
    "    return field_names\n",
    "\n",
    "async def main():\n",
    "    field_names = await fetch_form()\n",
    "    if not field_names:\n",
    "        return\n",
    "\n",
    "    # Prepare input data safely\n",
    "    input_data = {}\n",
    "    if len(field_names) >= 3:\n",
    "        input_data = {\n",
    "            field_names[0]: \"John Doe\",\n",
    "            field_names[1]: \"john@example.com\",\n",
    "            field_names[2]: \"This is a test message\"\n",
    "        }\n",
    "    else:\n",
    "        for name in field_names:\n",
    "            input_data[name] = f\"Sample for {name}\"\n",
    "\n",
    "    # Locate first field by OCR\n",
    "    target_label = field_names[0]\n",
    "    coord = None\n",
    "    for attempt in range(SCROLL_LIMIT):\n",
    "        shot = take_screenshot()\n",
    "        coord = find_text_coordinate_in_image(shot, target_label)\n",
    "        if coord:\n",
    "            print(f\"[FOUND] '{target_label}' at {coord} (attempt {attempt+1})\")\n",
    "            pyautogui.click(coord[0], coord[1])\n",
    "            fill_field(input_data[target_label])\n",
    "            input_data[target_label] = \"\"  # mark filled\n",
    "            break\n",
    "        print(f\"[INFO] '{target_label}' not found, scrolling...\")\n",
    "        pyautogui.scroll(SCROLL_AMOUNT)\n",
    "        time.sleep(SCROLL_DELAY)\n",
    "\n",
    "    # Fill remaining fields sequentially via Tab\n",
    "    for fname, fvalue in input_data.items():\n",
    "        if fvalue:\n",
    "            fill_field(fvalue)\n",
    "\n",
    "    # Press Enter to submit\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "# Run the main function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d09f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34bcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065f530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf82346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b58155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ff66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
