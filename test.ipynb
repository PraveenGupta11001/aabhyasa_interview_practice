{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b00707f",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f98e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Browser opened...\n",
      "[INFO] Required fields: ['name', 'phone', 'email', 'subject', 'message']\n",
      "[INFO] 'name' not found, scrolling...\n",
      "[FOUND] 'name' at (666, 846) (attempt 2)\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pyautogui\n",
    "import cv2\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "# ===== CONFIG =====\n",
    "URL = \"https://aabhyasa.com/contact\"\n",
    "SCROLL_AMOUNT = -5     # negative = scroll down\n",
    "SCROLL_DELAY = 0.8\n",
    "SCROLL_LIMIT = 200      # max scroll attempts before giving up\n",
    "\n",
    "# --- Screenshot helper ---\n",
    "def take_screenshot():\n",
    "    screenshot_path = \"screen.png\"\n",
    "    subprocess.run([\"gnome-screenshot\", \"-f\", screenshot_path])\n",
    "    time.sleep(1)\n",
    "    return screenshot_path\n",
    "\n",
    "# --- OCR extraction ---\n",
    "def extract_text(image_path):\n",
    "    img = Image.open(image_path).convert(\"L\")  # grayscale\n",
    "    img = img.point(lambda x: 0 if x < 130 else 255)  # threshold\n",
    "    text = pytesseract.image_to_string(img).lower()\n",
    "    return text\n",
    "\n",
    "# --- Find coordinates of text in image ---\n",
    "def find_text_coordinate_in_image(image_path, search_text):\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    img = img.point(lambda x: 0 if x < 130 else 255)\n",
    "\n",
    "    boxes = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "    for i in range(len(boxes['text'])):\n",
    "        if search_text.lower() in boxes['text'][i].lower():\n",
    "            x, y, w, h = boxes['left'][i], boxes['top'][i], boxes['width'][i], boxes['height'][i]\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            return (center_x, center_y)\n",
    "    return None\n",
    "\n",
    "# --- Fill field and press Tab ---\n",
    "def fill_field(value):\n",
    "    pyautogui.typewrite(value)\n",
    "    pyautogui.press(\"tab\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# --- Main automation ---\n",
    "def main():\n",
    "    # 1) Open browser\n",
    "    webbrowser.open(URL)\n",
    "    print(\"[INFO] Browser opened...\")\n",
    "    time.sleep(3)  # wait for load\n",
    "\n",
    "    # 2) Parse HTML for field names\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    res = requests.get(URL, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    form = soup.find(\"form\")\n",
    "\n",
    "    fields_bs4 = form.find_all([\"input\", \"textarea\"])\n",
    "    field_names = []\n",
    "    for tag in fields_bs4:\n",
    "        if tag.get(\"type\") in [\"submit\", \"hidden\", \"checkbox\", \"radio\"]:\n",
    "            continue\n",
    "        placeholder = tag.get(\"placeholder\") or tag.get(\"name\") or tag.get(\"id\")\n",
    "        if placeholder:\n",
    "            field_names.append(placeholder.strip())\n",
    "\n",
    "    print(\"[INFO] Required fields:\", field_names)\n",
    "\n",
    "    # 3) Ask user for data\n",
    "    # input_data = {}\n",
    "    input_data = {\n",
    "        \"name\": \"John Doe\",\n",
    "        \"phone\": \"9876543210\",\n",
    "        \"email\": \"john@example.com\",\n",
    "        \"subject\": \"Test Subject\",\n",
    "        \"message\": \"This is a test message\"\n",
    "    }\n",
    "    # for name in field_names:\n",
    "    #     val = input(f\"[INPUT] Enter value for '{name}': \")\n",
    "    #     input_data[name.lower()] = val.strip()\n",
    "    # time.sleep(3)\n",
    "\n",
    "    # 4) Locate first field (\"name\") by OCR\n",
    "    target_label = field_names[0]  # assume first field is \"name\"\n",
    "    coord = None\n",
    "    for attempt in range(SCROLL_LIMIT):\n",
    "        shot = take_screenshot()\n",
    "        coord = find_text_coordinate_in_image(shot, target_label)\n",
    "        if coord:\n",
    "            print(f\"[FOUND] '{target_label}' at {coord} (attempt {attempt+1})\")\n",
    "            pyautogui.click(coord[0], coord[1])\n",
    "            fill_field(input_data[target_label.lower()])\n",
    "            input_data[target_label.lower()] = \"\"  # mark filled\n",
    "            break\n",
    "        print(f\"[INFO] '{target_label}' not found, scrolling...\")\n",
    "        pyautogui.scroll(SCROLL_AMOUNT)\n",
    "        time.sleep(SCROLL_DELAY)\n",
    "\n",
    "    # 5) Fill remaining fields sequentially via Tab\n",
    "    for fname, fvalue in input_data.items():\n",
    "        if fvalue:\n",
    "            fill_field(fvalue)\n",
    "\n",
    "    # 6) Scroll to find \"submit\" button and click\n",
    "    pyautogui.press('enter')\n",
    "    # for attempt in range(SCROLL_LIMIT):\n",
    "    #     shot = take_screenshot()\n",
    "    #     coord = find_text_coordinate_in_image(shot, \"submit\")\n",
    "    #     if coord:\n",
    "    #         pyautogui.click(coord[0], coord[1])\n",
    "    #         print(\"[INFO] Submit button clicked.\")\n",
    "    #         break\n",
    "    #     print(\"[INFO] Scrolling to find submit...\")\n",
    "    #     pyautogui.scroll(SCROLL_AMOUNT)\n",
    "    #     time.sleep(SCROLL_DELAY)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a66f2d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546 694 516 20\n",
      "find_and_mark_text_on_screen('interview_p') find_and_mark_text_on_screen('interview_p') 306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(804, 704)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageDraw\n",
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def find_and_mark_text_on_screen(search_text, save_path=\"annotated_screenshot.png\"):\n",
    "    # Take screenshot\n",
    "    time.sleep(3)\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    screenshot_path = \"screen.png\"\n",
    "    screenshot.save(screenshot_path)\n",
    "\n",
    "    # Load screenshot in grayscale\n",
    "    img = Image.open(screenshot_path).convert(\"L\")\n",
    "    img_bin = img.point(lambda x: 0 if x < 130 else 255)\n",
    "\n",
    "    # Run OCR to get bounding boxes\n",
    "    boxes = pytesseract.image_to_data(img_bin, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "    draw_img = screenshot.copy()  # Color version for drawing\n",
    "    draw = ImageDraw.Draw(draw_img)\n",
    "\n",
    "    for i in range(len(boxes['text'])):\n",
    "        if search_text.lower() in boxes['text'][i].lower():\n",
    "            x, y, w, h = boxes['left'][i], boxes['top'][i], boxes['width'][i], boxes['height'][i]\n",
    "            print(x, y, w, h)\n",
    "            print(boxes['text'][i], boxes['text'][i], i)\n",
    "            # Draw rectangle\n",
    "            draw.rectangle([(x, y), (x + w, y + h)], outline=\"red\", width=2)\n",
    "\n",
    "            # Save annotated image\n",
    "            draw_img.save(save_path)\n",
    "\n",
    "            # Return center coordinates\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            return (center_x, center_y)\n",
    "\n",
    "    # If no match found\n",
    "    draw_img.save(save_path)  # Save screenshot anyway\n",
    "    return None\n",
    "INTERVIEW_P = ''\n",
    "find_and_mark_text_on_screen('interview_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ccb786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8057b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805b680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Required fields: ['name', 'email', 'message']\n",
      "[INFO] 'name' not found, scrolling...\n",
      "[FOUND] 'name' at (1012, 513) (attempt 2)\n",
      "name: \n",
      "email: john@example.com\n",
      "message: This is a test message\n",
      "{'name': '', 'email': 'john@example.com', 'message': 'This is a test message'}\n"
     ]
    }
   ],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pyautogui\n",
    "import cv2\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "# ===== CONFIG =====\n",
    "URL = \"https://portfolio-praveen-gupta.vercel.app/\"\n",
    "SCROLL_AMOUNT = -50     # negative = scroll down\n",
    "SCROLL_DELAY = 0.8\n",
    "SCROLL_LIMIT = 200      # max scroll attempts before giving up\n",
    "\n",
    "# --- Screenshot helper ---\n",
    "def take_screenshot():\n",
    "    screenshot_path = \"screen.png\"\n",
    "    subprocess.run([\"gnome-screenshot\", \"-f\", screenshot_path])\n",
    "    time.sleep(1)\n",
    "    return screenshot_path\n",
    "\n",
    "# --- OCR extraction ---\n",
    "def extract_text(image_path):\n",
    "    img = Image.open(image_path).convert(\"L\")  # grayscale\n",
    "    img = img.point(lambda x: 0 if x < 130 else 255)  # threshold\n",
    "    text = pytesseract.image_to_string(img).lower()\n",
    "    return text\n",
    "\n",
    "# --- Find coordinates of text in image ---\n",
    "def find_text_coordinate_in_image(image_path, search_text):\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    img = img.point(lambda x: 0 if x < 130 else 255)\n",
    "\n",
    "    boxes = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "    for i in range(len(boxes['text'])):\n",
    "        if search_text.lower() in boxes['text'][i].lower():\n",
    "            x, y, w, h = boxes['left'][i], boxes['top'][i]+25, boxes['width'][i], boxes['height'][i]+25\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            return (center_x, center_y)\n",
    "    return None\n",
    "\n",
    "# --- Fill field and press Tab ---\n",
    "def fill_field(value):\n",
    "    pyautogui.typewrite(value)\n",
    "    pyautogui.press(\"tab\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "# Allow nested event loops (needed for Jupyter/IPython)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def fetch_form():\n",
    "    session = AsyncHTMLSession()\n",
    "    webbrowser.open(URL)\n",
    "    # Load page\n",
    "    r = await session.get(URL)\n",
    "    \n",
    "    # Render JavaScript (wait up to 20s for React to finish)\n",
    "    await r.html.arender(timeout=20, sleep=2)\n",
    "    \n",
    "    # Parse final HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(r.html.html, \"html.parser\")\n",
    "    \n",
    "    # Get the <form> element\n",
    "    form = soup.find(\"form\")\n",
    "\n",
    "    fields_bs4 = form.find_all([\"input\", \"textarea\"])\n",
    "    field_names = []\n",
    "    for tag in fields_bs4:\n",
    "        if tag.get(\"type\") in [\"submit\", \"hidden\", \"checkbox\", \"radio\"]:\n",
    "            continue\n",
    "        placeholder = tag.text or tag.get(\"name\") or tag.get(\"id\")\n",
    "        if placeholder:\n",
    "            field_names.append(placeholder.strip())\n",
    "\n",
    "    print(\"[INFO] Required fields:\", field_names)\n",
    "    return field_names\n",
    "\n",
    "# In Jupyter, just \"await\" the function\n",
    "field_names = await fetch_form()\n",
    "input_data = {}\n",
    "input_data = {\n",
    "    f\"{field_names[0]}\": \"John Doe\",\n",
    "    f\"{field_names[1]}\": \"john@example.com\",\n",
    "    f\"{field_names[2]}\": \"This is a test message\"\n",
    "}\n",
    "\n",
    "# for name in field_names:\n",
    "#     val = input(f\"[INPUT] Enter value for '{name}': \")\n",
    "#     input_data[name.lower()] = val.strip()\n",
    "# time.sleep(3)\n",
    "\n",
    "# 4) Locate first field (\"name\") by OCR\n",
    "target_label = field_names[0]\n",
    "coord = None\n",
    "for attempt in range(SCROLL_LIMIT):\n",
    "    shot = take_screenshot()\n",
    "    coord = find_text_coordinate_in_image(shot, target_label)\n",
    "    if coord:\n",
    "        print(f\"[FOUND] '{target_label}' at {coord} (attempt {attempt+1})\")\n",
    "        pyautogui.click(coord[0], coord[1])\n",
    "        fill_field(input_data[target_label.lower()])\n",
    "        input_data[target_label.lower()] = \"\"  # mark filled\n",
    "        break\n",
    "    print(f\"[INFO] '{target_label}' not found, scrolling...\")\n",
    "    pyautogui.scroll(SCROLL_AMOUNT)\n",
    "    time.sleep(SCROLL_DELAY)\n",
    "\n",
    "# 5) Fill remaining fields sequentially via Tab\n",
    "for fname, fvalue in input_data.items():\n",
    "    print(f\"{fname}: {fvalue}\")\n",
    "    if fvalue:\n",
    "        fill_field(fvalue)\n",
    "\n",
    "print(input_data)\n",
    "\n",
    "# 6) Scroll to find \"submit\" button and click\n",
    "pyautogui.press('enter')\n",
    "# for attempt in range(SCROLL_LIMIT):\n",
    "#     shot = take_screenshot()\n",
    "#     coord = find_text_coordinate_in_image(shot, \"submit\")\n",
    "#     if coord:\n",
    "#         pyautogui.click(coord[0], coord[1])\n",
    "#         print(\"[INFO] Submit button clicked.\")\n",
    "#         break\n",
    "#     print(\"[INFO] Scrolling to find submit...\")\n",
    "#     pyautogui.scroll(SCROLL_AMOUNT)\n",
    "#     time.sleep(SCROLL_DELAY)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
